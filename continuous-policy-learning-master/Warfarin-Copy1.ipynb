{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trduong/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from off_pol_eval_functions import * \n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.spatial.distance import cdist\n",
    "import csv\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model, neighbors, ensemble, tree\n",
    "\n",
    "from warfarin_functions import * \n",
    "\n",
    "ntrs = np.arange(100,2501,100)\n",
    "runsper = 4\n",
    "runsperper = 25\n",
    "params = [ntr for ntr in ntrs for run in range(runsper)]\n",
    "\n",
    "myid = 0#int(sys.argv[1])\n",
    "# np.random.seed(myid)\n",
    "ntr = 1000#params[myid-1]\n",
    "\n",
    "f = open('warfrin.csv','rU')\n",
    "csvr = csv.reader(f, dialect=csv.excel)\n",
    "header = np.array(csvr.next())\n",
    "data   = list(csvr)\n",
    "f.close()\n",
    "\n",
    "# filter only to subjects that reached stable dose of warfarin\n",
    "# and stable observed INR\n",
    "data = [x for x in data if x[37]=='1' and x[38]!='NA' and x[39]!='NA']\n",
    "\n",
    "agegroups = sorted(set(x[8].replace('NA','') for x in data))\n",
    "\n",
    "xmap = lambda x: \\\n",
    "[\n",
    "    # gender 0\n",
    "    ('Male?',x[3]=='male'),\n",
    "    # race 1:4\n",
    "    ('White?',x[5]=='White'),\n",
    "    ('Asian?',x[5]=='Asian'),\n",
    "    ('Black?',x[5]=='Black or African American'),\n",
    "    # ethnicity 4\n",
    "    ('Non-hispanic?',x[7]=='not Hispanic or Latino'),\n",
    "    # age 5:7\n",
    "    ('Age group',agegroups.index(x[8]) if x[8] in agegroups else 0),\n",
    "    ('No age?',x[8] not in agegroups or agegroups.index(x[8]) == 0),\n",
    "    # height 7\n",
    "    ('Height',float(x[9]) if x[9] not in ('NA', '') else 0.),\n",
    "        # x[9] in ('NA', ''), # NA indicator\n",
    "    # weight 8\n",
    "    ('Weight',float(x[10]) if x[10] not in ('NA', '') else 0.),\n",
    "        # x[10] in ('NA', ''), # NA indicator\n",
    "    # BMI\n",
    "    ('BMI',float(x[10])*100.*100./float(x[9])/float(x[9]) if x[10] not in ('NA', '') and x[9] not in ('NA', '') else 0.),\n",
    "] + [# Indication for Warfarin Treatment 9:17\n",
    "    ('Indication for Warfarin Treatment: '+str(i), str(i) in x[11])\n",
    "    for i in range(1,9)\n",
    "# ] + [# comorbidities\n",
    "#     c in (y.strip() for y in x[12].lower().split('; '))\n",
    "#     for c in comorbidities\n",
    "] + [# diabetes 17:19\n",
    "    ('Diabetes=0?',x[13]=='0'),\n",
    "    ('Diabetes=1?',x[13]=='1'),\n",
    "] + [#Congestive Heart Failure and/or Cardiomyopathy 19:21\n",
    "    ('Congestive Heart Failure and/or Cardiomyopathy=0?',x[14]=='0'),\n",
    "    ('Congestive Heart Failure and/or Cardiomyopathy=1?',x[14]=='1'),\n",
    "] + [#Valve Replacement 21:23\n",
    "    ('Valve Replacement=0?',x[15]=='0'),\n",
    "    ('Valve Replacement=1?',x[15]=='1'),\n",
    "# ] + [# medications\n",
    "#   x[16]\n",
    "] + [\n",
    "    # Aspirin 24:26\n",
    "    ('aspirin=0?',x[17]=='0'),\n",
    "    ('aspirin=1?',x[17]=='1'),\n",
    "    # Acetaminophen or Paracetamol (Tylenol) 26:28\n",
    "    ('Acetaminophen=0?',x[18]=='0'),\n",
    "    ('Acetaminophen=1?',x[18]=='1'),\n",
    "    # Was Dose of Acetaminophen or Paracetamol (Tylenol) >1300mg/day 28:30\n",
    "    ('Acetaminophen hi dose=0?',x[19]=='0'),\n",
    "    ('Acetaminophen hi dose=1?',x[19]=='1'),\n",
    "    # Simvastatin (Zocor) 30:32\n",
    "    ('Simvastatin=0?',x[20]=='0'),\n",
    "    ('Simvastatin=1?',x[20]=='1'),\n",
    "    # Atorvastatin (Lipitor) 32:34\n",
    "    ('Simvastatin=0?',x[21]=='0'),\n",
    "    ('Simvastatin=1?',x[21]=='1'),\n",
    "    # Fluvastatin (Lescol) 34:36\n",
    "    ('Fluvastatin=0?',x[22]=='0'),\n",
    "    ('Fluvastatin=1?',x[22]=='1'),\n",
    "    # Lovastatin (Mevacor) 36:38\n",
    "    ('Lovastatin=0?',x[23]=='0'),\n",
    "    ('Lovastatin=1?',x[23]=='1'),\n",
    "    # Pravastatin (Pravachol) 38:40\n",
    "    ('Pravastatin=0?',x[24]=='0'),\n",
    "    ('Pravastatin=1?',x[24]=='1'),\n",
    "    # Rosuvastatin (Crestor) 40:42\n",
    "    ('Rosuvastatin=0?',x[25]=='0'),\n",
    "    ('Rosuvastatin=1?',x[25]=='1'),\n",
    "    # Cerivastatin (Baycol) 42:43\n",
    "    ('Cerivastatin=0?',x[26]=='0'),\n",
    "    ('Cerivastatin=1?',x[26]=='1'),\n",
    "    # Amiodarone (Cordarone)\n",
    "    ('Amiodarone=0?',x[27]=='0'),\n",
    "    ('Amiodarone=1?',x[27]=='1'),\n",
    "    # Carbamazepine (Tegretol)\n",
    "    ('Carbamazepine=0?',x[28]=='0'),\n",
    "    ('Carbamazepine=1?',x[28]=='1'),\n",
    "    # Phenytoin (Dilantin)\n",
    "    ('Phenytoin=0?',x[29]=='0'),\n",
    "    ('Phenytoin=1?',x[29]=='1'),\n",
    "    # Rifampin or Rifampicin\n",
    "    ('Rifampin=0?',x[30]=='0'),\n",
    "    ('Rifampin=1?',x[30]=='1'),\n",
    "    # Sulfonamide Antibiotics\n",
    "    ('Sulfonamide Antibiotics=0?',x[31]=='0'),\n",
    "    ('Sulfonamide Antibiotics=1?',x[31]=='1'),\n",
    "    # Macrolide Antibiotics\n",
    "    ('Macrolide Antibiotics=0?',x[32]=='0'),\n",
    "    ('Macrolide Antibiotics=1?',x[32]=='1'),\n",
    "    # Anti-fungal Azoles\n",
    "    ('Anti-fungal Azoles=0?',x[33]=='0'),\n",
    "    ('Anti-fungal Azoles=1?',x[33]=='1'),\n",
    "    # Herbal Medications, Vitamins, Supplements\n",
    "    ('Herbal Medications, Vitamins, Supplements=0?',x[34]=='0'),\n",
    "    ('Herbal Medications, Vitamins, Supplements=1?',x[34]=='1'),\n",
    "] + [\n",
    "    #smoker\n",
    "    ('Smoker=0?',x[40]=='0'),\n",
    "    ('Smoker=0?',x[40]=='1'),\n",
    "] + [\n",
    "    # CYP2C9 consensus\n",
    "    ('CYP2C9 *1/*1',x[59]=='*1/*1'),\n",
    "    ('CYP2C9 *1/*2',x[59]=='*1/*2'),\n",
    "    ('CYP2C9 *1/*3',x[59]=='*1/*3'),\n",
    "    ('CYP2C9 NA',x[59]=='' or x[59]=='NA'),\n",
    "    # VKORC1 -1639 consensus\n",
    "    ('VKORC1 -1639 A/A',x[60]=='A/A'),\n",
    "    ('VKORC1 -1639 A/G',x[60]=='A/G'),\n",
    "    ('VKORC1 -1639 G/G',x[60]=='G/G'),\n",
    "    # VKORC1 497 consensus\n",
    "    ('VKORC1 497 T/T',x[61]=='T/T'),\n",
    "    ('VKORC1 497 G/T',x[61]=='G/T'),\n",
    "    ('VKORC1 497 G/G',x[61]=='G/G'),\n",
    "    # VKORC1 1173 consensus\n",
    "    ('VKORC1 1173 T/T',x[62]=='T/T'),\n",
    "    ('VKORC1 1173 C/T',x[62]=='C/T'),\n",
    "    ('VKORC1 1173 C/C',x[62]=='C/C'),\n",
    "    # VKORC1 1542 consensus\n",
    "    ('VKORC1 1542 C/C',x[63]=='C/C'),\n",
    "    ('VKORC1 1542 C/G',x[63]=='C/G'),\n",
    "    ('VKORC1 1542 G/G',x[63]=='G/G'),\n",
    "    # VKORC1 3730 consensus\n",
    "    ('VKORC1 3730 A/A',x[64]=='A/A'),\n",
    "    ('VKORC1 3730 A/G',x[64]=='A/G'),\n",
    "    ('VKORC1 3730 G/G',x[64]=='G/G'),\n",
    "    # VKORC1 2255 consensus\n",
    "    ('VKORC1 2255 C/C',x[65]=='C/C'),\n",
    "    ('VKORC1 2255 C/T',x[65]=='C/T'),\n",
    "    ('VKORC1 2255 T/T',x[65]=='T/T'),\n",
    "    # VKORC1 -4451 consensus\n",
    "    ('VKORC1 -4451 C/C',x[66]=='C/C'),\n",
    "    ('VKORC1 -4451 A/C',x[66]=='A/C'),\n",
    "    ('VKORC1 -4451 A/A',x[66]=='A/A')\n",
    "#     ,\n",
    "#     ('Therapeutic Dose',float(x[38]) if x[38] not in ('NA', '') else 0.),\n",
    "#     ('INR On Therapeutic Dose',float(x[39]) if x[39] not in ('NA', '') else 0.),\n",
    "#     ('Target INR', float(x[35]) if x[35] not in ('NA', '') else 0. )\n",
    "]\n",
    "\n",
    "X       = np.array([zip(*xmap(x))[1] for x in data])\n",
    "Xnames  = np.array(zip(*xmap(data[0]))[0])\n",
    "goodidx = np.where( (X.std(0)>=.05)  )[0] #np.sort(np.hstack((np.where(X.std(0)>=.05)[0],np.where(Xnames=='BMI')[0])))\n",
    "X       = X[:,goodidx]\n",
    "Xnames  = Xnames[goodidx]\n",
    "# filter out by where BMI is nonzero \n",
    "goodbmi = np.where( (X[:,9] > 0.003) )[0]\n",
    "X       = X[goodbmi,:]\n",
    "# ytarget = np.array([float(x[38]) for x in data])/7.\n",
    "\n",
    "target_INR = np.array([float(x[35]) if x[35] not in ('NA', '') else 0. for x in data])\n",
    "therapeut_dose = np.array([float(x[38]) if x[38] not in ('NA', '') else 0. for x in data])\n",
    "obs_INR = np.array([float(x[39]) if x[39] not in ('NA', '') else 0. for x in data])\n",
    "\n",
    "target_INR = target_INR[goodbmi]; therapeut_dose = therapeut_dose[goodbmi]; obs_INR = obs_INR[goodbmi]\n",
    "\n",
    "n = X.shape[0]\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "International Normalised Ratio (INR) testing is well established as an integral part of warfarin treatment. INR has a critical role in maintaining the warfarin response within a therapeutic range, to provide the benefits of anticoagulation, while avoiding the risks of haemorrhage (Figure 1).\n",
    "\n",
    "The INR is defined as\n",
    "\n",
    "$$ INR =\\left( \\frac{\\text{Patient Prothrombin Time (sec)}}{\\text{Local Geometric Mean Prothrombin Time (sec)}}\\right)^{ISI} $$\n",
    "\n",
    "http://www.bpac.org.nz/BT/2010/November/inr.aspx\n",
    "\n",
    "In most situations the INR target is 2.5 (target range 2.0 â€“ 3.0). This range is appropriate for the prophylaxis or treatment of venous thromboembolism and reduction of the risk of systemic embolism for people with atrial fibrillation and valvular heart disease.5 In some situations higher ranges are more appropriate. The target INR may vary depending on individual clinical situations. The target INR for mechanical prosthetic valves is dependent on the type of valve replacement used.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-simulated dosages\n",
    "\n",
    "We can generate semi-simulated dosages from the true therapeutic dose by modeling dosage as a function of BMI and perturbing with some noise via a mixture model: \n",
    "\n",
    "$$T_i' = \\mu_{T^*} + \\sigma_{T^*} \\sqrt{\\theta} \\frac{x_{BMI}- \\mu_{BMI}}{\\sigma_{BMI}} + \\sqrt{(1 - \\theta)} \\sigma_{T^*} \\epsilon$$\n",
    "\n",
    "Suppose that the counterfactual outcome is given by a quadratic penalty to the INR outcome of the observed therapeutic dose: \n",
    "\n",
    "$$y_i' = y_i^* + \\frac{(T_i' - T_i)^2sgn(T_i' - T_i)}{max(T_i^2, T_i'^2)}$$\n",
    "\n",
    "This model also yields the propensity score for assigning the counterfactual dose. \n",
    "### Propensity score given our treatment generation model from BMI : \n",
    "   \n",
    "where $\\epsilon \\sim N(0,1)$ and $Z_{BMI} = \\frac{x_{BMI} - \\mu_{BMI}}{\\sigma_{BMI}}$\n",
    "\n",
    "$$ \\mathbb{P}[T_i'=t \\mid x_{bmi} ] = \\mathbb{P}\\left[\\epsilon = \\frac{t - \\mu_T^* - \\sigma_T^* \\sqrt{\\theta}Z_{BMI}}{\\sqrt{1 - \\theta}} \\right]$$\n",
    "\n",
    "\n",
    "### Dosing policy evaluation and optimization \n",
    "\n",
    "In any observational dataset, we will not have access to the full counterfactual distribution of outcomes. Previous analysis of the Warfarin dataset has focused on predicting being in a discrete bin of the \"correct\" therapeutic dose, e.g. Hamsa Bastani, Bertsimas/Kallus introducing 0-1 loss for being in the same bin. Other work (Chen, Zeng, Kosorok) look at a direct model of the outcome and directly penalize \n",
    "\n",
    "We leverage the rich previous study of the impacts of warfarin dosing, treating these models and analyses as \"oracle information\" we use to simulate realistic outcome data. We consider previous studies analyzing the effect that different INR levels have on the odds ratios for complications including ischemic stroke and hemorrhagic complications. The intensity of anticoagulation induced by warfarin therapy trades off between decreased stroke prevention at low levels of INR (less effective anticoagulation), and increased risk of intracranial bleeding in over-anticoagulation regimes. Various factors such as patient age and pre-existing health conditions (previous stroke) affect patient risk in ways that have been previously studied, but we do not directly account for in this simulated study.\n",
    "\n",
    "Proposed model: \n",
    "\n",
    "* Generate simulated doses as $T_i' = \\mu_{T^*} + \\sigma_{T^*} \\sqrt{\\theta} \\frac{x_{BMI}- \\mu_{BMI}}{\\sigma_{BMI}} + \\sqrt{(1 - \\theta)} \\sigma_{T^*} \\epsilon$\n",
    "* Simulate INR response to dose adjustment (inversion of dosage guidelines) <https://depts.washington.edu/anticoag/home/content/warfarin-maintenance-dosing-nomogram>: $\\hat{y}(T_i')$\n",
    "* Compute expected risk as a function of how the odds ratio is affected by INR [ACC/AHA/ESC 2006 guidelines for the management of patients with atrial fibrillation](https://academic.oup.com/europace/article/8/9/651/530495/ACC-AHA-ESC-2006-guidelines-for-the-management-of): $R(\\hat{y}(T_i')$\n",
    "* Compare $R(\\hat{y}(\\tau(X_i))$ across policies $\\tau$\n",
    "\n",
    "\n",
    "Optimization Question: \n",
    "\n",
    "If one generates a dataset of simulated dose adjustments and INR responses in this fashion, can you recover the therapeutic dose (or an optimal linear treatment policy which is similar) if you do off-policy optimization? What kind of treatment policy does the optimization return? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_loss(sim_dose, therapeut_dose, obs_INR):\n",
    "    return (np.abs(therapeut_dose - sim_dose))+ np.random.normal()*0.1*mu_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.013676277413794\n",
      "17.21068727968127\n",
      "[36.44625628 39.76205743 30.56830155 ... 27.92877481 30.83598384\n",
      " 18.31584311]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global values \n",
    "mu_dose = np.mean(therapeut_dose)\n",
    "std_dose = np.std(therapeut_dose)\n",
    "mu_bmi = np.mean(X[:,9])\n",
    "std_bmi = np.std(X[:,9])\n",
    "\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X[:,9].reshape([n,1]), therapeut_dose.reshape([n,1]))\n",
    "\n",
    "theta = 0.5\n",
    "eps = np.random.normal(size=n)\n",
    "\n",
    "# eps = np.random.randn(n)\n",
    "bmi_Z = (X[:,9] - mu_bmi)/std_bmi\n",
    "\n",
    "# fit on centered model\n",
    "regr = linear_model.LinearRegression(fit_intercept = False)\n",
    "regr.fit(bmi_Z.reshape([n,1]), therapeut_dose.reshape([n,1]))\n",
    "\n",
    "\n",
    "sim_dose = mu_dose  + (np.sqrt(theta)*bmi_Z*std_dose + np.sqrt(1-theta)*std_dose*eps) \n",
    "sim_dose[sim_dose < 0 ] = - sim_dose[sim_dose < 0 ] \n",
    "print np.std(sim_dose)\n",
    "print std_dose \n",
    "\n",
    "plt.hist(therapeut_dose[therapeut_dose<150],alpha=0.5,color='g',label= 'true_dose', normed=True)\n",
    "plt.hist(sim_dose,alpha = 0.5, label = \"simulated dosage\", normed=True)\n",
    "plt.legend()\n",
    "\n",
    "y_counter = np.asarray(simulated_loss(sim_dose, therapeut_dose, obs_INR))\n",
    "print y_counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score given our treatment generation model from BMI : \n",
    "   \n",
    "where $\\epsilon \\sim N(0,1)$ and $Z_{BMI} = \\frac{x_{BMI} - \\mu_{BMI}}{\\sigma_{BMI}}$\n",
    "\n",
    "$$ \\mathbb{P}[T_i'=t \\mid x_{bmi} ] = \\mathbb{P}\\left[\\epsilon = \\frac{t - \\mu_T^* - \\sigma_T^* \\sqrt{\\theta}Z_{BMI}}{\\sqrt{1 - \\theta}} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.569864487260983e-07\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epanechnikov_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fe4087b7c78f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_dose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_bins'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel_int_func'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepanechnikov_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel_func'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepanechnikov_kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'oracle_func'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounterfactual_y_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epanechnikov_int' is not defined"
     ]
    }
   ],
   "source": [
    "# Add to param dictionary: \n",
    "# therapeutic dose (\"oracle values\") \n",
    "# observed INR  (\"oracle values\")\n",
    "#! FIXME will require global access to therapeutic doses/ \n",
    "def generated_Q(bmi, T, theta, NULL): \n",
    "    # centeredaround mu_dose with scale stddev of dose\n",
    "    theta = 0.5\n",
    "    Z_bmi = (bmi-mu_bmi)/std_bmi\n",
    "    return norm.pdf( T, loc = mu_dose + std_dose*np.sqrt(theta)*Z_bmi, scale = np.sqrt(1-theta) )\n",
    "\n",
    "print generated_Q(30,40,0.9,std_dose)\n",
    "\n",
    "d = 1\n",
    "t_lo =0\n",
    "t_hi = max(therapeut_dose)\n",
    "data = { 'n': n, 'y': obs_INR,'Q': generated_Q, 'x': X[:,9],'x_samp':X[:,9],  'd': d, 'T': therapeut_dose,'t_lo': t_lo ,'t_hi': t_hi  }\n",
    "data['tau'] = sim_dose\n",
    "data['h'] = 3; data['n_bins'] = 10\n",
    "data['kernel_int_func'] = epanechnikov_int\n",
    "data['kernel_func'] = epanechnikov_kernel\n",
    "data['oracle_func'] = counterfactual_y_eval\n",
    "data['threshold'] = 0.01 \n",
    "print np.mean(counterfactual_y_eval(**data))\n",
    "\n",
    "print off_policy_evaluation(**data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.659662705000006\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Systematically evaluate over a treatment space defined by a linear treatment policy\n",
    "'''\n",
    "n_trials = 10\n",
    "n_treatments = 10\n",
    "t_lo = 0 ; t_hi = max(therapeut_dose) \n",
    "print t_hi / np.min(X[:,9])\n",
    "beta_space = np.linspace(0.5,2, n_treatments)\n",
    "off_pol_evals = np.zeros(n_treatments)\n",
    "oracle_evals = np.zeros(n_treatments)\n",
    "discrete_off_pol_evals = np.zeros(n_treatments)\n",
    "\n",
    "def simulated_loss(sim_dose, therapeut_dose, obs_INR):\n",
    "    return (np.abs(therapeut_dose - sim_dose))+ np.random.normal()*0.1*mu_dose\n",
    "\n",
    "\n",
    "data['y'] = simulated_loss(sim_dose, therapeut_dose, obs_INR)\n",
    "data['y_samp'] = simulated_loss(sim_dose, therapeut_dose, obs_INR)\n",
    "data['T_samp'] = sim_dose \n",
    "\n",
    "# for beta_ind, beta in enumerate(beta_space):\n",
    "#     tau = np.clip(beta*data['x'] , t_lo, t_hi).flatten()\n",
    "#     data['tau'] = tau\n",
    "#     oracle_evals[beta_ind] = np.mean(simulated_loss(tau, therapeut_dose, obs_INR))\n",
    "#     off_pol_evals[beta_ind] = off_policy_evaluation(**data)\n",
    "#     discrete_off_pol_evals[beta_ind] = off_pol_disc_evaluation(discretize_tau_policy , **data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b1bbeee7c90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(beta_space, oracle_evals,color='b')\n",
    "plt.scatter(beta_space, off_pol_evals,color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a more sophisticated model with more covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ec6a4a795e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# subXnames = Xnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an index"
     ]
    }
   ],
   "source": [
    "train_var = [5,9]+range(18,40)\n",
    "subframe = X[:,[5,9]+range(18,40)]\n",
    "subXnames = Xnames[[5,9]+range(18,40)]\n",
    "# subframe = X \n",
    "# subXnames = Xnames\n",
    "d = subframe.shape[1]\n",
    "trainind = np.random.choice(range(n),size =  round(0.8*n),replace = False)\n",
    "train = subframe[trainind]\n",
    "test_mask = np.ones(n, dtype=bool)\n",
    "test_mask[trainind] = False\n",
    "test = subframe[test_mask,:]\n",
    "\n",
    "y = simulated_loss(sim_dose[trainind], therapeut_dose[trainind], obs_INR[trainind])\n",
    "def generated_Q_multid_X(x,t,t_lo,t_hi): \n",
    "    return generated_Q(x,t,t_lo,t_hi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9f1483404c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulated_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_dose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtherapeut_dose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_INR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobs_INR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerated_Q_multid_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x_full'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x_samp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'd'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtherapeut_dose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m't_lo'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt_lo\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m't_hi'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt_hi\u001b[0m  \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel_int_func'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepanechnikov_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainind' is not defined"
     ]
    }
   ],
   "source": [
    "y = simulated_loss(sim_dose[trainind], therapeut_dose[trainind], obs_INR[trainind])\n",
    "h=4\n",
    "d = X.shape[1]\n",
    "train_data = { 'n': train.shape[0],'h': h, 'y': obs_INR,'Q': generated_Q_multid_X,'x_full': X, 'x': X,'x_samp': X[trainind,:],  'd': d, 'T': therapeut_dose[trainind],'t_lo': t_lo ,'t_hi': t_hi  }\n",
    "train_data['kernel_int_func'] = epanechnikov_int\n",
    "train_data['T_samp'] = np.array(sim_dose[trainind],order='F'); train_data['y_samp'] = np.array(simulated_loss(sim_dose[trainind], therapeut_dose[trainind], obs_INR[trainind]),order='F')\n",
    "train_data['kernel_func'] = epanechnikov_kernel\n",
    "train_data['DATA_TYPE'] = 'warfarin'\n",
    "train_data['BMI_IND'] = 9\n",
    "train_data['inds'] = trainind\n",
    "train_data['threshold'] = 0.01\n",
    "\n",
    "bounds = [(0, np.mean(therapeut_dose)/np.mean(X[:,i])) for i in range(d) ]\n",
    "bnds = tuple(tuple(x) for x in bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subframe data (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = simulated_loss(sim_dose[trainind], therapeut_dose[trainind], obs_INR[trainind])\n",
    "d = subframe.shape[1]\n",
    "train_data = { 'n': train.shape[0],'h': 4, 'y': obs_INR,'Q': generated_Q,'x_full': subframe, 'x': np.array(train,order='F'),'x_samp': np.array(train,order='F'), 'T_samp': sim_dose[trainind], 'd': d, 'T': therapeut_dose[trainind],'t_lo': t_lo ,'t_hi': t_hi  }\n",
    "train_data['kernel_int_func'] = epanechnikov_int\n",
    "train_data['T_samp'] = np.array(sim_dose[trainind],order='F'); train_data['y_samp'] = np.array(simulated_loss(sim_dose[trainind], therapeut_dose[trainind], obs_INR[trainind]),order='F')\n",
    "train_data['kernel_func'] = epanechnikov_kernel\n",
    "train_data['DATA_TYPE'] = 'warfarin'\n",
    "train_data['BMI_IND'] = 1\n",
    "train_data['inds'] = trainind\n",
    "train_data['threshold'] = 0.01\n",
    "\n",
    "bounds = [(0, np.mean(therapeut_dose)/np.mean(subframe[:,i])) for i in range(d) ]\n",
    "bnds = tuple(tuple(x) for x in bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "t_lo = 0 \n",
    "t_hi = max(therapeut_dose)\n",
    "\n",
    "beta_d = np.random.rand(d)\n",
    "h = 10\n",
    "n_train = train.shape[0]\n",
    "# train_data['oracle_func'] = counterfactual_y_eval\n",
    "\n",
    "def pol_eval_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    data['tau'] = tau\n",
    "    return off_policy_evaluation(**data)\n",
    "\n",
    "def oracle_eval_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    return np.mean( simulated_loss(tau,therapeut_dose,obs_INR) )\n",
    "\n",
    "# print off_pol_epan_lin_grad(beta_d, train_data)\n",
    "LAMBDA = 0.4\n",
    "def var_regularized_pol_eval_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    data['tau'] = tau\n",
    "    return off_policy_evaluation(**data) + LAMBDA * np.linalg.norm(beta,2) + LAMBDA * off_policy_variance(**data)\n",
    "\n",
    "def var_regularized_oracle_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    return np.mean( simulated_loss(tau,therapeut_dose,obs_INR) )\n",
    "\n",
    "def off_pol_var_lin_grad(beta, *args):\n",
    "    \"\"\"\n",
    "    Compute a gradient for special case of Epanechnikov kernel and linear policy tau\n",
    "    \"\"\"\n",
    "    \n",
    "    d = len(beta) \n",
    "    params = dict(args[0]); n = params['n']\n",
    "    THRESH = params['threshold']\n",
    "    y_out = params['y']; x = params['x']; h = params['h'];Q = params['Q']; n = params['n']; t_lo = params['t_lo'];  t_hi = params['t_hi']\n",
    "    kernel = params['kernel_func'];kernel_int =  params['kernel_int_func']\n",
    "    y_out = params['y_samp']; T = params['T_samp']; x = params['x_samp']\n",
    " \n",
    "    #! FIXME x vs xsamp\n",
    "    tau = np.dot(beta, params['x'].T)\n",
    "    params['tau'] = tau; params['beta'] = beta\n",
    "    clip_tau = np.clip(tau, t_lo, t_hi)\n",
    "    BMI_IND = params.get('BMI_IND'); THRESH = params['threshold'] # propensity score for warfarin data evaluations \n",
    "    \n",
    "\n",
    "    [f, g, nabla_f, nabla_g] = f_g(**params)\n",
    "    # compute gradient vector via quotient rule\n",
    "    if g < THRESH: \n",
    "        g = THRESH  \n",
    "    grad_estimator = np.asarray((g*nabla_f - f*nabla_g) / g**2 )\n",
    "    var_grad = -1*f *grad_estimator\n",
    "    var_grad_term1 = 0 \n",
    "    for i in range(n): \n",
    "        if (params.get('DATA_TYPE') == 'warfarin'): \n",
    "            Q_i = Q(x[i,BMI_IND], T[i], t_lo, t_hi)\n",
    "        else: \n",
    "            Q_i = Q(x[i], T[i], t_lo, t_hi)\n",
    "        if (abs(clip_tau[i] - t_lo) <= h):\n",
    "            alpha = kernel_int((t_lo-clip_tau[i])/h, 1)\n",
    "        elif (abs(clip_tau[i] - t_hi) <= h):\n",
    "            alpha = kernel_int(-1,  (t_hi - clip_tau[i])/h )\n",
    "        else:\n",
    "            alpha = 1\n",
    "#         Qs[i] = kernel( (clip_tau[i] - T[i])/h )/max(Q_i,THRESH)\n",
    "        if abs((clip_tau[i] - T[i])/h) >= 1:\n",
    "            var_grad_term1 += 0 # don't add anything to partial derivatives \n",
    "        else:\n",
    "            var_grad_term1 += 2* (kernel( (clip_tau[i] - T[i])/h )*1.0 * y_out[i]/max(Q_i,THRESH) * 1.0/alpha)*(.75*x[i]*y_out[i]/max(Q_i,THRESH)*(1 - 1.0*(clip_tau[i] - T[i])/h ))\n",
    "    var_grad_term1 = var_grad_term1*1.0/n\n",
    "    var_grad += var_grad_term1\n",
    "    return np.asarray((g*nabla_f - f*nabla_g) / g**2 ) + 2*LAMBDA*beta + 2*var_grad \n",
    "\n",
    "def plot_training_set_hist(beta, x, therapeut_dose, sim_dose, title, policy_label): \n",
    "    plt.hist(np.abs(np.dot(beta, x.T)  - therapeut_dose ),range=[0,80],alpha = 0.5,label=policy_label)\n",
    "    plt.hist(np.abs(sim_dose - therapeut_dose),alpha = 0.5,range=[0,80],color = 'g',label='original simulated dose' )\n",
    "    plt.legend()\n",
    "    plt.title(title,y=1.08)\n",
    "    plt.ylabel('frequencies')\n",
    "    plt.ylim((0, 1800))\n",
    "    plt.xlabel('Absolute value of distance between recommended and therapeutic dose')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['y'] = train_data['y']-np.mean(train_data['y'])\n",
    "train_data['y_samp'] = train_data['y_samp']-np.mean(train_data['y_samp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "d = X.shape[1]\n",
    "n_restarts = 1\n",
    "vals = np.zeros(n_restarts)\n",
    "betas = [None]*n_restarts\n",
    "i = 0 \n",
    "while i <= n_restarts: \n",
    "    print i\n",
    "\n",
    "    beta_d = 0.8*(mu_dose / (d*np.mean(X[trainind,:],axis=0))) +0.2*np.random.uniform(size=d,low=np.zeros(d), high = [bnds[k][1]*1.0/d for k in range(d) ])\n",
    "    \n",
    "#     beta_d = mu_dose / (d*np.mean(X[trainind,:],axis=0))\n",
    "#     oracle_res = minimize(pol_eval_wrapper, x0 = beta_d, jac = off_pol_epan_lin_grad, bounds = bnds , options={'disp':True,'gtol':1e-4}, args=train_data.items())  \n",
    "#     try: \n",
    "    oracle_res = minimize(var_regularized_pol_eval_wrapper, x0 = beta_d, bounds = bnds , options={'disp':True,'gtol':1e-3}, args=train_data.items())  \n",
    "\n",
    "#         oracle_res = minimize(var_regularized_pol_eval_wrapper, x0 = beta_d, jac = off_pol_epan_lin_grad, bounds = bnds , options={'disp':True,'gtol':1e-4}, args=train_data.items())  \n",
    "    betas[i] = oracle_res.x\n",
    "    print oracle_res.x\n",
    "    vals[i] = oracle_res.fun\n",
    "    print oracle_res.fun\n",
    "    i += 1\n",
    "#     except: \n",
    "#         print \"Gradient error\"\n",
    "    \n",
    "pickle.dump(oracle_res.x, open(str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")) + 'empirical_opt_beta-v2', 'wb'))\n",
    "best_off_pol_beta = betas[np.argmin(vals)]\n",
    "best_off_pol_val = vals[np.argmin(vals)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_off_pol_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_off_pol_beta = pickle.load(open('2017-05-16_23-32empirical_opt_beta-v2',\"rb\"))\n",
    "\n",
    "plot_training_set_hist(best_off_pol_beta, X[trainind,:], therapeut_dose[trainind], sim_dose[trainind],\"Comparison of empirically optimal treatment policy vs original dose\",\"empirically optimal training policy\")\n",
    "plot_training_set_hist(best_off_pol_beta, X[test_mask,:], therapeut_dose[test_mask], sim_dose[test_mask],\"Comparison of empirically optimal treatment policy vs original dose\",\"empirically optimal training policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "d = X.shape[1]\n",
    "beta = cvx.Variable(d)\n",
    "# Implement a thresholded loss\n",
    "#cost = cvx.sum_entries(cvx.max_elemwise(cvx.abs(X[trainind,:]*beta - therapeut_dose[trainind]) - therapeut_dose[trainind]*0.1, 0))/n*1.0\n",
    "# normal l1 loss (median regression)\n",
    "cost = cvx.sum_entries(cvx.abs(X[trainind,:]*beta - therapeut_dose[trainind]))/n*1.0\n",
    "\n",
    "constraints = [beta >= 0]\n",
    "for i in range(d): \n",
    "    constraints += [beta[i] <= np.mean(therapeut_dose[trainind])/np.mean(X[trainind,i]) ]\n",
    "prob = cvx.Problem(cvx.Minimize(cost), constraints)\n",
    "\n",
    "prob.solve()\n",
    "print beta.value\n",
    "prescient_beta = beta.value.flatten().T\n",
    "prescient_beta = np.ravel(prescient_beta).T\n",
    "\n",
    "pickle.dump(prescient_beta, open(str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")) + 'prescient-beta-v2', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_eval_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    INDS = data['inds']\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x_samp'].T) , t_lo, t_hi).flatten()\n",
    "    return np.mean( simulated_loss(tau,therapeut_dose[INDS],obs_INR[INDS]) )\n",
    "\n",
    "beta_d = np.random.rand(d)\n",
    "train_data['inds'] = trainind\n",
    "oracle_actual_oracle_res = minimize(oracle_eval_wrapper, x0 = beta_d, bounds = bnds , options={'disp':True,'gtol':1e-4}, args=train_data.items())  \n",
    "pickle.dump(oracle_actual_oracle_res.x, open('oracle_opt_beta', 'wb'))\n",
    "print oracle_actual_oracle_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print oracle_actual_oracle_res\n",
    "print \"off pol oracle\"\n",
    "print oracle_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build direct estimate and use 'regress and compare' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_w_dose = np.column_stack((X, sim_dose))\n",
    "X_w_dose.shape\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(X[trainind,:],y=therapeut_dose[trainind])\n",
    "train_data['x_full'] = X_w_dose\n",
    "train_data['rf'] = clf\n",
    "\n",
    "d = X.shape[1]\n",
    "# Regression and compare \n",
    "# Iterate through dataset and choose dose maximizing dose response \n",
    "\n",
    "# n = len(trainind)\n",
    "# ts = np.linspace(0,80,160)\n",
    "# best_taus_for_x = np.zeros(n)\n",
    "# for i in range(n): \n",
    "#     if (i%500 == 0): \n",
    "#         print i \n",
    "#     drf_vals = [clf.predict( np.append(X_w_dose[trainind[i],0:d-1], np.asarray(t)).reshape(1,-1)) for t in ts ]\n",
    "#     best_tau = np.argmin(drf_vals)\n",
    "#     best_taus_for_x[i] = ts[best_tau]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=X.shape[1]\n",
    "sort_inds = np.argsort(clf.feature_importances_)[::-1][:d]\n",
    "\n",
    "pickle.dump(sort_inds, open('important_features_fm_regr.p','wb'))\n",
    "print Xnames[sort_inds[0:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_taus_for_x, open(str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")) + 'dm_best_treatments-RC-train.p', 'wb'))\n",
    "pickle.dump(best_taus_for_x_test, open(str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")) + 'dm_best_treatments-RC-test.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_taus_for_x = pickle.load(open('2017-05-16_15-41dm_best_treatments-RC-train.p'))\n",
    "best_taus_for_x_test = pickle.load(open('2017-05-16_15-41dm_best_treatments-RC-test.p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optimizing direct method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [ (0, np.mean(therapeut_dose)/(np.sqrt(d)*np.mean(X_w_dose[:,i]))) for i in range(d) ]\n",
    "bnds = tuple(tuple(x) for x in bounds)\n",
    "def dm_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    INDS = data['inds']\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    clf = train_data['rf']\n",
    "    tau = np.clip(np.dot(beta, data['x_full'][trainind,:].T), t_lo, t_hi).flatten()\n",
    "    counterfactual_X = np.column_stack((data['x_full'][trainind,0:d-1], tau))\n",
    "    reg_lambda = 3\n",
    "    return 100* (np.mean( clf.predict( counterfactual_X )) + reg_lambda * np.linalg.norm( beta, 1 )) \n",
    "\n",
    "\n",
    "\n",
    "beta_d = np.random.uniform(low = np.zeros(d), high = [bnds[i][1] for i in range(d) ], size = d)\n",
    "epsilon = np.ones(d)*1e-2\n",
    "dm_res = minimize(dm_wrapper, x0 = beta_d, jac= None, bounds = bnds , options={'disp':True,'gtol':1e-8, 'eps':np.ones(d)*1e-1}, args=train_data.items())  \n",
    "\n",
    "pickle.dump(dm_res.x, open(str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")) + 'dm_beta-v2', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(dm_res.x, X_w_dose[trainind,:].T)\n",
    "\n",
    "print dm_res.x\n",
    "print len(dm_res.x[0:len(dm_res.x)-1])\n",
    "print Xnames[np.where(dm_res.x[0:len(dm_res.x)-2] > 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "\n",
    "list_data = [ subframe[trainind,i] for i in range(d) ] + [sim_dose[trainind]]\n",
    "print list_data\n",
    "print len(list_data)\n",
    "print [len(list_data[i]) for i in range(len(list_data))]\n",
    "kernel_regr = KernelReg(endog = [y.reshape([len(trainind),1])], exog=list_data, var_type=['c']*len(list_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(np.hstack([subframe[trainind], sim_dose[trainind].reshape([len(trainind),1])]) )\n",
    "\n",
    "df.to_csv(\"train_data.csv\", header = list(subXnames)+[\"sim_dose\"],index=None)\n",
    "ydf = pd.DataFrame(y) \n",
    "ydf.to_csv('y.csv',header='y',index =None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete off-policy evaluation and optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_dose(dose): \n",
    "    discretized_dose = np.zeros(len(dose))\n",
    "    for i in range(len(dose)): \n",
    "        if dose[i] < 21: \n",
    "            discretized_dose[i] = 0 \n",
    "        elif dose[i] < 49: \n",
    "            discretized_dose[i] = 1\n",
    "        elif dose[i] >= 49: \n",
    "            discretized_dose[i] = 2\n",
    "    return discretized_dose\n",
    "\n",
    "disc_therapeutic_dose = discretize_dose(therapeut_dose)\n",
    "disc_sim_dose = discretize_dose(sim_dose) \n",
    "\n",
    "def generated_Q_wrapper(T, bmi, theta, NULL): \n",
    "    theta = 0.5\n",
    "    # centeredaround mu_dose with scale stddev of dose\n",
    "    Z_bmi = (bmi-mu_bmi)/std_bmi\n",
    "    return norm.pdf( T, loc = mu_dose + std_dose*np.sqrt(theta)*Z_bmi, scale = np.sqrt(1-theta) )\n",
    "\n",
    "min_T = min(sim_dose)\n",
    "max_T = max(sim_dose)\n",
    "# y is still the same loss information ( distance from treatment ) \n",
    "def integrated_gps(bmi, T, min_T, max_T ): \n",
    "    theta = 0.5\n",
    "    GPS = np.zeros(len(T))\n",
    "    for i in range(len(T)): \n",
    "        if T[i] < 21: \n",
    "            GPS[i] = scipy.integrate.quad( generated_Q_wrapper, 5, 21, args=(bmi[i], theta, theta) )[0]\n",
    "        elif T[i] < 49: \n",
    "            GPS[i] = scipy.integrate.quad( generated_Q_wrapper, 21, 49, args=(bmi[i], theta, theta) )[0]\n",
    "        elif T[i] >= 49: \n",
    "            GPS[i] = scipy.integrate.quad( generated_Q_wrapper, 49, 80, args=(bmi[i], theta, theta) )[0]\n",
    "    if i % 500 == 0: \n",
    "        print i \n",
    "    return GPS\n",
    "\n",
    "integrated_propensity_scores = integrated_gps(X[trainind,9], sim_dose[trainind], min_T, max_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute POEM \n",
    "import sys\n",
    "sys.path.append('./POEM-norm/')\n",
    "import DatasetReader, Skylines\n",
    "\n",
    "Xtrain = X[trainind,:]\n",
    "ttrain = disc_sim_dose.astype(int)[trainind]\n",
    "gps = np.asarray([generated_Q_wrapper(sim_dose[i], X[trainind,9][i], 0.5, 0.5 ) for i in range(len(trainind))])\n",
    "# all 0-1\n",
    "# gps = integrated_propensity_scores\n",
    "ytrain = y\n",
    "Xtest = X[test_mask,:]\n",
    "\n",
    "\n",
    "\n",
    "mydata = DatasetReader.BanditDataset(None,False)\n",
    "mydata.trainFeatures        = np.hstack((Xtrain.copy(),np.ones((len(Xtrain),1))))\n",
    "mydata.sampledLabels        = np.zeros((len(ttrain),max(ttrain)+1))\n",
    "mydata.sampledLabels[range(len(ttrain)),ttrain] = 1.\n",
    "mydata.trainLabels          = np.empty(mydata.sampledLabels.shape)\n",
    "mydata.sampledLoss          = ytrain.copy()\n",
    "mydata.sampledLoss         -= mydata.sampledLoss.min()\n",
    "mydata.sampledLoss         /= mydata.sampledLoss.max()\n",
    "# computed on training set \n",
    "mydata.sampledLogPropensity = np.log(gps)\n",
    "#ones_like vs ones_line? \n",
    "mydata.testFeatures              = np.hstack((np.ones_like(Xtest),np.ones((len(Xtest),1))))\n",
    "mydata.testLabels                = np.array([])\n",
    "mydata.createTrainValidateSplit(validateFrac = 0.25)\n",
    "pool = None \n",
    "coef = None\n",
    "\n",
    "maj = Skylines.PRMWrapper(mydata, n_iter = 1000, tol = 1e-6, minC = 0, maxC = -1, minV = 0, maxV = -1,\n",
    "                            minClip = 0, maxClip = 0, estimator_type = 'Vanilla', verbose = True,\n",
    "                            parallel = pool, smartStart = coef)\n",
    "maj.calibrateHyperParams()\n",
    "maj.validate()\n",
    "Xtest1 = np.hstack((Xtest,np.ones((len(Xtest),1))))\n",
    "rec = Xtest1.dot(maj.labeler.coef_).argmax(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POEM-norm\n",
    "\n",
    "mydata = DatasetReader.BanditDataset(None,False)\n",
    "mydata.trainFeatures        = np.hstack((Xtrain.copy(),np.ones((len(Xtrain),1))))\n",
    "mydata.sampledLabels        = np.zeros((len(ttrain),max(ttrain)+1))\n",
    "mydata.sampledLabels[range(len(ttrain)),ttrain] = 1.\n",
    "mydata.trainLabels          = np.empty(mydata.sampledLabels.shape)\n",
    "mydata.sampledLoss          = ytrain.copy()\n",
    "mydata.sampledLoss         -= mydata.sampledLoss.min()\n",
    "mydata.sampledLoss         /= mydata.sampledLoss.max()\n",
    "mydata.sampledLogPropensity = np.log(gps)\n",
    "mydata.testFeatures              = np.hstack((np.ones_like(Xtest),np.ones((len(Xtest),1))))\n",
    "mydata.testLabels                = np.array([])\n",
    "mydata.createTrainValidateSplit(validateFrac = 0.25)\n",
    "pool = None \n",
    "coef = None\n",
    "\n",
    "maj = Skylines.PRMWrapper(mydata, n_iter = 1000, tol = 1e-6, minC = 0, maxC = -1, minV = 0, maxV = -1,\n",
    "                            minClip = 0, maxClip = 0, estimator_type = 'SelfNormal', verbose = True,\n",
    "                            parallel = pool, smartStart = coef)\n",
    "maj.calibrateHyperParams()\n",
    "maj.validate()\n",
    "Xtest1 = np.hstack((Xtest,np.ones((len(Xtest),1))))\n",
    "rec = Xtest1.dot(maj.labeler.coef_).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "imputed_Q = LogisticRegression(multi_class = \"multinomial\",solver='lbfgs')\n",
    "# Impute probability of low/medium/high simulated dose\n",
    "imputed_Q.fit(subframe[trainind], disc_sim_dose[trainind])\n",
    "\n",
    "recentered_loss = discretized_loss - np.mean(discretized_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_pol_disc_given_disc_evaluation(policy, **params):\n",
    "    THRESH = 0.000001\n",
    "    y_out = params['y']; x = params['x_samp']; h = params['h']; Q = params['Q']; n = params['n']; t_lo = params['t_lo']; t_hi = params['t_hi']\n",
    "    imputed_Q = params['imputed_Q']\n",
    "    if ('y_samp' in params.keys()):\n",
    "        y_out = params['y_samp'].flatten()\n",
    "    if ('T_samp' in params.keys()):\n",
    "        T = params['T_samp'].flatten()\n",
    "    else:\n",
    "        T = params['T'].flatten()\n",
    "\n",
    "    t_lo = min(T)\n",
    "    t_hi = max(T)\n",
    "    \n",
    "    T_binned = discretize_dose(T)\n",
    "    bins = range(unique(T_binned)) + 1\n",
    "    bin_means = [T[T_binned == i].mean() for i in range(1, len(bins))]\n",
    "    tau_bins = discretize_dose(params['tau'])\n",
    "    loss = 0\n",
    "    treatment_overlap = np.where(np.equal(tau_bins, T_binned))[0]\n",
    "\n",
    "    for ind in treatment_overlap:\n",
    "        # use a discrete probability \n",
    "        loss += y_out[ind]/max(Q_i,THRESH)\n",
    "    n_overlap = len(treatment_overlap)\n",
    "    if n_overlap == 0:\n",
    "        print \"no overlap\"\n",
    "        return np.inf\n",
    "    return loss/(1.0*n_overlap)\n",
    "\n",
    "\n",
    "def oracle_eval_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    INDS = data['inds']\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    return np.mean( simulated_loss(tau,therapeut_dose[INDS],obs_INR[INDS]) )\n",
    "\n",
    "\n",
    "beta_d = np.random.rand(d)\n",
    "train_data['inds'] = trainind\n",
    "oracle_actual_oracle_res = minimize(oracle_eval_wrapper, x0 = beta_d, bounds = bnds , options={'disp':True,'gtol':1e-4}, args=train_data.items())  \n",
    "pickle.dump(oracle_actual_oracle_res.x, open('oracle_opt_beta', 'wb'))\n",
    "print oracle_actual_oracle_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hist results of giving mu_dose amount of treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(np.abs(np.mean(sim_dose[trainind]) - therapeut_dose[trainind] ).T,range=[0,80],alpha = 0.5,label='best-in-class treatment policy')\n",
    "plt.hist(np.abs(sim_dose[trainind] - therapeut_dose[trainind]),range=[0,80],alpha = 0.5,color = 'g',label='original simulated dose' )\n",
    "plt.title(\"Histogram of training set performance of assigning mean of simulated dose\",y=1.08)\n",
    "plt.legend()\n",
    "plt.ylabel('frequencies')\n",
    "plt.ylim((0,1800))\n",
    "plt.xlabel('Absolute value of distance between recommended and therapeutic dose')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.abs(np.mean(sim_dose[test_mask]) - therapeut_dose[test_mask] ).T,range=[0,80],alpha = 0.5,label='best-in-class treatment policy')\n",
    "plt.hist(np.abs(sim_dose[test_mask] - therapeut_dose[test_mask]),range=[0,80],alpha = 0.5,color = 'g',label='original simulated dose' )\n",
    "plt.title(\"Histogram of training set performance of assigning mean of simulated dose\",y=1.08)\n",
    "plt.legend()\n",
    "plt.ylabel('frequencies')\n",
    "plt.ylim((0,1800))\n",
    "plt.xlabel('Absolute value of distance between recommended and therapeutic dose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(np.abs(np.asarray((train*prescient_beta).flatten()) - therapeut_dose[trainind] ).T,range=[0,80],alpha = 0.5,label='best-in-class treatment policy')\n",
    "plt.hist(np.abs(sim_dose[trainind] - therapeut_dose[trainind]),range=[0,80],alpha = 0.5,color = 'g',label='original simulated dose' )\n",
    "plt.title(\"Histogram of training set performance of best-in-class treatment policy\",y=1.08)\n",
    "plt.legend()\n",
    "plt.ylabel('frequencies')\n",
    "plt.ylim((0,1800))\n",
    "plt.xlabel('L1 deviation from 10% range of therapeutic dose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(prescient_beta).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram results of off-policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_set_hist(best_off_pol_beta, X[trainind,:], therapeut_dose[trainind], sim_dose[trainind], \"Training set performance of empirically optimal treatment policy\")\n",
    "\n",
    "print \"test set performance\"\n",
    "plot_training_set_hist(best_off_pol_beta, X[test_mask,:], therapeut_dose[test_mask], sim_dose[test_mask], \"Test set performance of empirically optimal treatment policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_set_hist(prescient_beta, X[trainind,:], therapeut_dose[trainind], sim_dose[trainind], 'Training set performance of best-in-class treatment policy')\n",
    "\n",
    "print \"test set performance\"\n",
    "plot_training_set_hist(prescient_beta, X[test_mask,:], therapeut_dose[test_mask], sim_dose[test_mask], 'Test set performance of best-in-class treatment policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sum(np.abs(sim_dose[trainind] - therapeut_dose[trainind]))\n",
    "print sum(np.abs(np.dot(oracle_actual_oracle_res.x, train.T) - therapeut_dose[trainind]))\n",
    "print sum(np.abs(np.dot(oracle_res.x, train.T) - therapeut_dose[trainind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray((np.dot(best_off_pol_beta, train.T) - sim_dose[trainind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(best_off_pol_beta, train.T)\n",
    "\n",
    "plt.hist(np.abs(np.dot(best_off_pol_beta, train.T)  - therapeut_dose[trainind] ),range=[0,80],alpha = 0.5,label='empirically optimal treatment policy')\n",
    "plt.hist(np.abs(sim_dose[trainind] - therapeut_dose[trainind]),alpha = 0.5,range=[0,80],color = 'g',label='original simulated dose' )\n",
    "plt.legend()\n",
    "plt.title('Histogram of training set performance of empirically optimal treatment policy',y=1.08)\n",
    "plt.ylabel('frequencies')\n",
    "plt.ylim((0, 1800))\n",
    "plt.xlabel('L1 deviation from 10% range of therapeutic dose')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print test.shape\n",
    "plt.hist(np.abs(np.dot(oracle_actual_oracle_res.x, test.T) - therapeut_dose[test_mask]),range=[0,50],alpha = 0.7,color='r', label='best-in-class treatment policy')\n",
    "plt.hist(np.abs(np.dot(oracle_res.x, test.T) - therapeut_dose[test_mask]),range=[0,50],alpha = 0.7,color='g', label='empirically optimal treatment policy')\n",
    "plt.hist(np.abs(sim_dose[test_mask] - therapeut_dose[test_mask]),range=[0,50],alpha = 0.5, color = 'b' ,label = 'original simulated dose')\n",
    "plt.title(\"Histogram of out-of-sample test performance (deviation from therapeutic dose)\",y=1.08)\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('L1 deviation from 10% range of therapeutic dose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct method regress and compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_set_hist(dm_res.x, X_w_dose[trainind,:], therapeut_dose[trainind], sim_dose[trainind], 'Test set performance of direct method (random forest) policy optimization', 'random forest policy')\n",
    "plot_training_set_hist(dm_res.x, X_w_dose[test_mask,:], therapeut_dose[test_mask], sim_dose[test_mask], 'Test set performance of direct method (random forest) policy optimization', 'random forest policy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0,80,160)\n",
    "n_test = sum(test_mask)\n",
    "best_taus_for_x_test = np.zeros(n_test)\n",
    "for i in range(n_test): \n",
    "\n",
    "    drf_vals = [clf.predict( np.append(X_w_dose[test_mask,:][i,0:d-1], np.asarray(t)).reshape(1,-1)) for t in ts ]\n",
    "    best_tau = np.argmin(drf_vals)\n",
    "    best_taus_for_x_test[i] = ts[best_tau]\n",
    "    \n",
    "    if (i%100 == 0): \n",
    "        print i \n",
    "        plt.plot(ts, drf_vals)\n",
    "    \n",
    "print best_taus_for_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "i=100\n",
    "drf_vals = [clf.predict( np.append(X_w_dose[test_mask][i,0:d-1], np.asarray(t)).reshape(1,-1)) for t in ts ]\n",
    "plt.plot(ts,drf_vals)\n",
    "print ts[np.argmin(drf_vals)]\n",
    "plt.figure()\n",
    "\n",
    "i = 100 \n",
    "drf_vals = [clf.predict( np.append(X_w_dose[test_mask[i],0:d-1], np.asarray(t)).reshape(1,-1)) for t in ts ]\n",
    "plt.plot(ts,drf_vals)\n",
    "\n",
    "print ts[np.argmin(drf_vals)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off policy evaluation regress \\& compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0,80,160)\n",
    "n_test = sum(test_mask)\n",
    "best_taus_for_x_test = np.zeros(n_test)\n",
    "for i in range(n_test): \n",
    "    drf_vals = [clf.predict( np.append(X_w_dose[test_mask,:][i,0:d-1], np.asarray(t)).reshape(1,-1)) for t in ts ]\n",
    "    best_tau = np.argmin(drf_vals)\n",
    "    best_taus_for_x_test[i] = ts[best_tau]\n",
    "    \n",
    "    if (i%100 == 0): \n",
    "        print i \n",
    "        plt.plot(ts, drf_vals)\n",
    "    \n",
    "print best_taus_for_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.median(np.abs(sim_dose[test_mask] - therapeut_dose[test_mask]))\n",
    "print np.median(np.abs(np.dot(oracle_actual_oracle_res.x, test.T) - therapeut_dose[test_mask]))\n",
    "print np.median(np.abs(np.dot(oracle_res.x, test.T) - therapeut_dose[test_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boxplot of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)\n",
    "\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# prescient_norm = np.abs(np.dot(prescient_beta, X[test_mask,:].T)  - therapeut_dose[test_mask] )\n",
    "# off_pol_norm = np.abs(np.dot(best_off_pol_beta, X[test_mask,:].T)  - therapeut_dose[test_mask] )\n",
    "# mean_dose_pol_norm = np.abs(np.mean(sim_dose[test_mask]) - therapeut_dose[test_mask] )\n",
    "# dm_norms = np.abs(np.dot(dm_res.x, X_w_dose[test_mask,:].T)  - therapeut_dose[test_mask] )\n",
    "# original = np.abs(sim_dose[test_mask] - therapeut_dose[test_mask])\n",
    "\n",
    "prescient_norm =(np.dot(prescient_beta, X[test_mask,:].T)  - therapeut_dose[test_mask] )\n",
    "off_pol_norm = (np.dot(best_off_pol_beta, X[test_mask,:].T)  - therapeut_dose[test_mask] )\n",
    "mean_dose_pol_norm = (np.mean(sim_dose[test_mask]) - therapeut_dose[test_mask] )\n",
    "dm_norms = (best_taus_for_x_test  - therapeut_dose[test_mask] )\n",
    "original = (sim_dose[test_mask] - therapeut_dose[test_mask])\n",
    "\n",
    "\n",
    "norms = [prescient_norm, off_pol_norm, dm_norms, mean_dose_pol_norm, original]\n",
    "\n",
    "plt.figure(figsize=(4.5,3))\n",
    "plt.ylabel('Differences btn. policy and therapeutic dose')\n",
    "flierprops = dict(linestyle='-',color='black')\n",
    "\n",
    "# prefer to turn off mean line\n",
    "bp_dict = plt.boxplot(norms,sym='', showmeans = False, meanline=False)\n",
    "\n",
    "for whisker in bp_dict['whiskers']:\n",
    "    whisker.set(color='#000000',linestyle='solid')\n",
    "for box in bp_dict['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='#000000')\n",
    "for ind,line in enumerate(bp_dict['medians']):\n",
    "    # get position data for median line\n",
    "    x, y = line.get_xydata()[1] # top of median line\n",
    "    if ind == 4: \n",
    "        plt.text(x-0.18, y+4, '%.1f' % y, horizontalalignment='center') # draw above, centered\n",
    "    # overlay median value\n",
    "    else:\n",
    "        plt.text(x+0.2, y+4, '%.1f' % y, horizontalalignment='center') # draw above, centered\n",
    "\n",
    "top = 60\n",
    "bottom = -60\n",
    "plt.ylim(bottom, top)\n",
    "# plt.title('Boxplot of distances between policy-recommended doses and therapeutic doses',y = 1.2)\n",
    "plt.axhline(y=np.median(mean_dose_pol_norm), xmin=0,xmax=1,color='g', ls='dashdot',linewidth=0.7)\n",
    "plt.axhline(y=0, xmin=0,xmax=1,color='g',alpha=0.3, ls='dashed',linewidth=0.7)\n",
    "plt.xticks([1, 2, 3,4,5], ['Best-In-Class', 'Continuous OPE', 'DM (Random Forest R&C)', 'Mean dose', 'Original doses'])\n",
    "plt.xticks(rotation=25)\n",
    "plt.show()\n",
    "\n",
    "plt.violinplot(norms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_off_pol_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"medians\"\n",
    "print np.median(prescient_norm)\n",
    "print np.median(off_pol_norm )\n",
    "print np.median(mean_dose_pol_norm )\n",
    "print np.median(dm_norms)\n",
    "print np.median(original)\n",
    "\n",
    "print \"means\"\n",
    "print_f_(np.mean)\n",
    "\n",
    "def print_f_(func): \n",
    "    print func(prescient_norm)\n",
    "    print func(off_pol_norm )\n",
    "    print func(mean_dose_pol_norm )\n",
    "    print func(dm_norms)\n",
    "    print func(original)\n",
    "               \n",
    "               \n",
    "print \"sum of absolute values of differences\"\n",
    "print_f_(lambda x: sum(abs(x)))\n",
    "print \"standard deviations \"\n",
    "print_f_(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_pol_dose_test = np.dot(best_off_pol_beta, X[test_mask,:].T\n",
    "plt.scatter(X[test_mask][:,9], best_taus_for_x_test,color='r',alpha=0.3,label='treatment dose from DM')\n",
    "plt.scatter(X[test_mask][:,9], np.dot(best_off_pol_beta, X[test_mask,:].T),color='g',alpha=0.3 , label='treatment dose from OPE')\n",
    "plt.scatter(X[test_mask][:,9], therapeut_dose[test_mask],color='b',alpha=0.1 , label='therapeutic dose')\n",
    "\n",
    "\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel('dose')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Robust estimator from DM, IPW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy \n",
    "def DR_wrapper(beta, args): \n",
    "    data = dict(args)\n",
    "    INDS = data['inds']\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    clf = train_data['rf']\n",
    "    # train beta which gets best treatment policy for direct estimator \n",
    "    tau = np.clip(np.dot(beta, data['x'][INDS,:].T), t_lo, t_hi).flatten()\n",
    "    # concatenate 1st (d) colunns of full X \n",
    "    counterfactual_X = np.column_stack((data['x_full'][INDS,0:-1], tau))\n",
    "    reg_lambda = 3\n",
    "    data = dict(args)\n",
    "    # evaluate rhat(\\tau_i, x_i) \n",
    "    dm = np.mean( clf.predict( counterfactual_X ))\n",
    "    t_lo = data['t_lo']; t_hi = data['t_hi']\n",
    "    tau = np.clip(np.dot(beta, data['x'].T) , t_lo, t_hi).flatten()\n",
    "    data['tau'] = tau\n",
    "    \n",
    "    # evaluate rhat(t_i, x_i) on observed treatments\n",
    "    T_X = np.column_stack((data['x_full'][INDS,0:-1], sim_dose[INDS]))\n",
    "    old_y = data_copy['y_samp']\n",
    "    data['y_samp'] = data['y_samp'] - clf.predict( T_X )\n",
    "    ipw = off_policy_evaluation(**data)\n",
    "    data['y_samp'] = old_y \n",
    "    \n",
    "    return 100*(dm + ipw) \n",
    "\n",
    "d = X.shape[1]\n",
    "beta_d = np.random.rand(d)\n",
    "train_data['inds'] = trainind\n",
    "\n",
    "bounds = [(0, np.mean(therapeut_dose)/(np.sqrt(d)*np.mean(X_w_dose[:,i]))) for i in range(d) ]\n",
    "bnds = tuple(tuple(x) for x in bounds)\n",
    "\n",
    "oracle_DR_res = minimize(DR_wrapper, x0 = beta_d, bounds = bnds , options={'disp':True,'gtol':1e-3}, args=train_data.items())  \n",
    "pickle.dump(DR_wrapper.x, open('oracle_DR_beta', 'wb'))\n",
    "print oracle_DR_res"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
