{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import cProfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import torch\n",
    "import numpy\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports IRM_games_regression to fit C-LRG\n",
    "from irm_games_regression import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = \"../ERM_per_env/IRMv1_regression\" #(path name to inside IRMv1_regression folder )\n",
    "import sys\n",
    "sys.path.insert(1, path_name)\n",
    "from sem_Sep8 import ChainEquationModel\n",
    "from models_crossval_Sep8 import *\n",
    "# from IRM_exhaustive_argparse_hper_wo_disc_Sep8 import *\n",
    "# from main_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IRM_exhaustive_argparse_hper_wo_disc_Sep8 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class erm_model_per_env:\n",
    "    def __init__(self, model_list,  num_epochs, batch_size, learning_rate):\n",
    "        \n",
    "        self.model_list        = model_list\n",
    "        self.num_epochs   = num_epochs\n",
    "        self.batch_size   = batch_size\n",
    "        self.learning_rate=learning_rate\n",
    "        self.model_final_list = []\n",
    "        self.index_diff_list = []\n",
    "        self.w_final_list         = []\n",
    "        self.w_final_select       = []\n",
    "         \n",
    "    \n",
    "    def fit(self, data_tuple_list, diff_threshold):\n",
    "        learning_rate = self.learning_rate\n",
    "        num_epochs = self.num_epochs\n",
    "        n_e  = len(data_tuple_list)\n",
    "        \n",
    "        model_list = self.model_list\n",
    "    ### fit the model\n",
    "        for i in range(n_e):\n",
    "            print (i)\n",
    "            x_in = data_tuple_list[i][0]\n",
    "            y_in = data_tuple_list[i][1]\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "\n",
    "            model_list[i].compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"\n",
    "                                                         ])\n",
    "\n",
    "            model_list[i].fit(x_in, y_in,  epochs=num_epochs, batch_size=batch_size)\n",
    "  \n",
    "\n",
    "        self.model_list = model_list\n",
    "    \n",
    "#         diff_threshold = self.diff_threshold\n",
    "        \n",
    "        n_f = np.shape(model_list[0].weights[0].numpy())[0]\n",
    "        index_sel = []\n",
    "        vec_diff = np.abs(erm_per_env.model_list[1].weights[0].numpy().T-erm_per_env.model_list[0].weights[0].numpy().T)[0]\n",
    "        index_diff = np.where(vec_diff<diff_threshold)[0]\n",
    "        print (index_diff)\n",
    "        x_in_c = data_tuple_list[0][0]\n",
    "        for i in range(1,n_e):\n",
    "            x_c = data_tuple_list[i][0]\n",
    "            x_in_c = np.concatenate((x_in_c, x_c), axis=0)\n",
    "        y_in_c = data_tuple_list[0][1]\n",
    "        for i in range(1,n_e):\n",
    "            y_c = data_tuple_list[i][1]\n",
    "            y_in_c = np.concatenate((y_in_c, y_c), axis=0)\n",
    "        e_in_c = data_tuple_list[0][2]\n",
    "        for i in range(1,n_e):\n",
    "            e_c = data_tuple_list[i][2]\n",
    "            e_in_c = np.concatenate((e_in_c, e_c), axis=0) \n",
    "        \n",
    "        x_in_c1 = x_in_c[:,index_diff]\n",
    "        model_final = keras.Sequential([\n",
    "            keras.layers.Dense(1)])\n",
    "        \n",
    "        model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    " loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "        model_final.fit(x_in_c1, y_in_c,  epochs=num_epochs, batch_size=batch_size)\n",
    "        \n",
    "        self.model_final_list.append(model_final)\n",
    "        self.index_diff_list.append(index_diff) \n",
    "        m = np.shape(x_in_c)[1]\n",
    "        print (\"m: \" + str(m))\n",
    "        w_final = np.zeros(m)\n",
    "        \n",
    "        w_final[index_diff] = model_final.weights[0].numpy().T[0]\n",
    "        self.w_final_list.append(w_final)\n",
    "    \n",
    "    def validate_fit(self, data_tuple_list, data_tuple_list_valid, threshold_list):\n",
    "        \n",
    "        n_e  = len(data_tuple_list)\n",
    "        x_in_c = data_tuple_list_valid[0][0]\n",
    "        for i in range(1,n_e):\n",
    "            x_c = data_tuple_list_valid[i][0]\n",
    "            x_in_c = np.concatenate((x_in_c, x_c), axis=0)\n",
    "        y_in_c = data_tuple_list_valid[0][1]\n",
    "        for i in range(1,n_e):\n",
    "            y_c = data_tuple_list_valid[i][1]\n",
    "            y_in_c = np.concatenate((y_in_c, y_c), axis=0)\n",
    "        e_in_c = data_tuple_list_valid[0][2]\n",
    "        for i in range(1,n_e):\n",
    "            e_c = data_tuple_list_valid[i][2]\n",
    "            e_in_c = np.concatenate((e_in_c, e_c), axis=0) \n",
    "        \n",
    "#         x_in_c1 = x_in_c[:,index_diff]\n",
    "        \n",
    "        ind = 0\n",
    "        cur_error_min = 1e7\n",
    "        for threshold in threshold_list:\n",
    "            loss_object = tf.keras.losses.MeanSquaredError()\n",
    "            self.fit(data_tuple_list, threshold)\n",
    "            index_diff = self.index_diff_list[ind]\n",
    "            model_cur = self.model_final_list[ind]\n",
    "            error = loss_object(y_in_c, model_cur(x_in_c[:,index_diff]))\n",
    "            if(error<=cur_error_min):\n",
    "                error = cur_error_min\n",
    "                ind_min = ind\n",
    "        \n",
    "        self.w_final_select.append(self.w_final_list[ind_min])\n",
    "            \n",
    "        \n",
    "        \n",
    "    def evaluate(self, data_tuple_test):\n",
    "        ##### evaluations jmtd\n",
    "        x_test = data_tuple_test[0]\n",
    "        y_test = data_tuple_test[1]\n",
    "        x_in   = self.x_in\n",
    "        y_in   = self.y_in\n",
    "        \n",
    "        model = self.model\n",
    "        train_accuracy= tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        test_accuracy= tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        ytr_ = model.predict(x_in)\n",
    "        train_acc =  np.float(train_accuracy(y_in, ytr_))\n",
    "\n",
    "        yts_ = model.predict(x_test)\n",
    "\n",
    "        test_acc  =  np.float(test_accuracy(y_test, yts_))\n",
    "        \n",
    "        self.train_acc = train_acc\n",
    "        self.test_acc  = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ERM\n",
    "n_samples = 1000\n",
    "args = {\"seed\":8,\"setup_sem\": \"chain\", \"dim\": 10, \"n_samples\": n_samples, \"n_reps\": 1, \"skip_reps\": 0, \"print_vectors\": 1, \"n_iterations\": 100000, \"lr\": 1e-3, \"verbose\": 0,  \"alpha\": 0.05, \"setup_scramble\":0, \"setup_hetero\":1, \"setup_hidden\":1, \"env_list\":[0.2,2.0], \"verbose\":0, \"child\":0, \"noise_identity\":1, \"ones\":1}\n",
    "\n",
    "args[\"methods\"] = \"ERM\"\n",
    "all_solutions, all_environments, msolution, sem_solution = run_experiment_ERM(args)\n",
    "true_sol = sem_solution.detach().numpy().T[0]\n",
    "ERM_sol = msolution.detach().numpy()[0]\n",
    "print (\"Distance of ERM soln \" +str(np.linalg.norm(ERM_sol- true_sol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Run C-LRG \n",
    "data_tuple_list = convert_regn_np_format(all_environments)\n",
    "n_e=2\n",
    "model_list = [] \n",
    "for e in range(n_e):\n",
    "\n",
    "    model_list.append(keras.Sequential([\n",
    "            keras.layers.Dense(1)\n",
    "    ]))\n",
    "\n",
    "num_epochs       = 500\n",
    "batch_size       = 128\n",
    "learning_rate    = 0.005\n",
    "bound            = 2\n",
    "plot_flag        = 'false'\n",
    "F_game = fixed_irm_game_model_regression(model_list, learning_rate, num_epochs, batch_size, bound, plot_flag) \n",
    "\n",
    "\n",
    "## Run C-LRG\n",
    "F_game.fit(data_tuple_list)\n",
    "fgamesol = 0.0\n",
    "for e in range(n_e):\n",
    "    fgamesol += F_game.model_list[e].weights[0]\n",
    "print (\"Distance of C-LRG soln \" + str(np.linalg.norm(fgamesol.numpy().T[0]- true_sol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ERM-per-environment\n",
    "n_e=2\n",
    "n_samples = 800\n",
    "args = {\"seed\":1,\"setup_sem\": \"chain\", \"dim\": 10, \"n_samples\": n_samples, \"n_reps\": 1, \"skip_reps\": 0, \"print_vectors\": 1, \"n_iterations\": 100000, \"lr\": 1e-3, \"verbose\": 0,  \"alpha\": 0.05, \"setup_scramble\":0, \"setup_hetero\":1, \"setup_hidden\":1, \"env_list\":[0.2,2.0], \"verbose\":0, \"child\":0, \"noise_identity\":0, \"ones\":1}\n",
    "\n",
    "args[\"methods\"] = \"ERM\"\n",
    "all_solutions, all_environments, msolution, sem_solution = run_experiment_ERM(args)\n",
    "true_sol = sem_solution.detach().numpy().T[0]\n",
    "ERM_sol = msolution.detach().numpy()[0]\n",
    "print (np.linalg.norm(ERM_sol- true_sol))\n",
    "\n",
    "\n",
    "data_tuple_list = convert_regn_np_format(all_environments)\n",
    "\n",
    "n_samples = 200\n",
    "args = {\"seed\":1,\"setup_sem\": \"chain\", \"dim\": 10, \"n_samples\": n_samples, \"n_reps\": 1, \"skip_reps\": 0, \"print_vectors\": 1, \"n_iterations\": 100000, \"lr\": 1e-3, \"verbose\": 0,  \"alpha\": 0.05, \"setup_scramble\":0, \"setup_hetero\":1, \"setup_hidden\":1, \"env_list\":[0.2,2.0], \"verbose\":0, \"child\":0, \"noise_identity\":0, \"ones\":1}\n",
    "\n",
    "args[\"methods\"] = \"ERM\"\n",
    "all_solutions, all_environments, msolution, sem_solution = run_experiment_ERM(args)\n",
    "true_sol = sem_solution.detach().numpy().T[0]\n",
    "ERM_sol = msolution.detach().numpy()[0]\n",
    "print (np.linalg.norm(ERM_sol- true_sol))\n",
    "\n",
    "data_tuple_list_valid= convert_regn_np_format(all_environments)\n",
    "\n",
    "\n",
    "model_list = [] \n",
    "for e in range(n_e):\n",
    "\n",
    "    model_list.append(keras.Sequential([\n",
    "            keras.layers.Dense(1)\n",
    "    ]))\n",
    "num_epochs       = 200\n",
    "batch_size       = 128\n",
    "learning_rate    = 0.005\n",
    "bound            = 5\n",
    "plot_flag        = 'false'\n",
    "erm_per_env      = erm_model_per_env(model_list,  num_epochs, batch_size, learning_rate) \n",
    "erm_per_env.validate_fit(data_tuple_list, data_tuple_list_valid, [0.05,0.1,0.2])\n",
    "# erm_per_env.fit(data_tuple_list, 0.1)\n",
    "\n",
    "print (\"Distance of ERM per env soln \"+ str(np.linalg.norm(erm_per_env.w_final_select[0]-true_sol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
